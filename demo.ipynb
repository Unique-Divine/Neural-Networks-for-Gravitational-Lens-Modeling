{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import scipy.ndimage\n",
    "from scipy import misc\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "import numpy as np\n",
    "import numpy.matlib as ml\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "import scipy.io\n",
    "slim = tf.contrib.slim\n",
    "sess = tf.InteractiveSession()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Galaxy Zoo: [[paper]](https://ui.adsabs.harvard.edu/abs/2008MNRAS.389.1179L/abstract), [[dataset description]](https://data.galaxyzoo.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_out = 5    #number of output parameters being predicted\n",
    "global numpix_side\n",
    "numpix_side = 192   #number of image pixels on the side\n",
    "global max_noise_rms, max_psf_rms , max_cr_intensity\n",
    "max_trainoise_rms = 0.1 # maximum rms of noise in training data\n",
    "max_testnoise_rms = 0.1 # maximum rms of noise in test or validation data\n",
    "max_noise_rms = max_testnoise_rms\n",
    "\n",
    "max_psf_rms = 0.08/0.04  # maximum Gaussian PSF rms (in pixels)\n",
    "max_cr_intensity = 0.5 # maximum scaling for cosmic ray and artefact maps\n",
    "\n",
    "global constant_noise_rms\n",
    "variable_noise_rms = True  #if True, the noise rms will be chosen randomly for each sample with a max of max_noise_rms (above)\n",
    "\n",
    "# cycle_batch_size = how many examples to read at a time (here it's equal to the batch size)\n",
    "cycle_batch_size = 50   \n",
    "num_test_samples = 1000\n",
    "\n",
    "global pix_res\n",
    "# pixel size in arcsec\n",
    "pix_res = 0.04\n",
    "L_side = pix_res * numpix_side\n",
    "\n",
    "global arcs_data_path_1, arcs_data_path_2 , test_data_path_1 , test_data_path_2 , CRay_data_path\n",
    "global lens_data_path_1, lens_data_path_2, testlens_data_path_1, testlens_data_path_2\n",
    "\n",
    "global min_unmasked_flux\n",
    "min_unmasked_flux = 0.75\n",
    "\n",
    "global num_data_dirs\n",
    "num_data_dirs = 3\n",
    "\n",
    "num_training_samples = 100000\n",
    "max_num_test_samples = 10000\n",
    "arcs_data_path_1 = 'data/SAURON_TEST/'\n",
    "arcs_data_path_2 = arcs_data_path_1\n",
    "arcs_data_path_3 = arcs_data_path_1\n",
    "test_data_path_1 = 'data/SAURON_TEST/'\n",
    "test_data_path_2 = test_data_path_1\n",
    "test_data_path_3 = test_data_path_1\n",
    "\n",
    "lens_data_path_1 = 'data/SAURON_TEST/'\n",
    "lens_data_path_2 = lens_data_path_1\n",
    "lens_data_path_3 = lens_data_path_1\n",
    "testlens_data_path_1 = 'data/SAURON_TEST/'\n",
    "testlens_data_path_2 = testlens_data_path_1\n",
    "testlens_data_path_3 = testlens_data_path_1\n",
    "\n",
    "CRay_data_path   = 'data/CosmicRays/'\n",
    "\n",
    "global max_xy_range   # xy range of center of the lens. The image is shifted in a central area with a side of max_xy_range (arcsec) during training or testing\n",
    "max_xy_range = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open(\"./get_data.py\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, numpix_side*numpix_side])   #placeholder for input image\n",
    "y_ = tf.placeholder(tf.float32, shape=[None,num_out])    #placeholder for output parameters during training\n",
    "x_image0 = tf.reshape(x, [-1,numpix_side,numpix_side,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing image intensity bias: filter image with a 4X4 filter and remove from image\n",
    "MASK = tf.abs(tf.sign(x_image0))\n",
    "XX =  x_image0 +  ( (1-MASK) * 1000.0)\n",
    "bias_measure_filt = tf.constant((1.0/16.0), shape=[4, 4, 1, 1])\n",
    "bias_measure = tf.nn.conv2d( XX , bias_measure_filt , strides=[1, 1, 1, 1], padding='VALID')\n",
    "im_bias = tf.reshape( tf.reduce_min(bias_measure,axis=[1,2,3]) , [-1,1,1,1] )\n",
    "x_image = x_image0 - (im_bias * MASK )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct all models (networks):\n",
    "exec(open(\"./ensai_model.py\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# make an instance of AlexNet (model 9):\n",
    "with tf.variable_scope(\"ENSAI\"):\n",
    "    y_conv = model_9(x_image,scope=\"EN_Model9\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from data/trained_weights/model_9.ckpt\n"
     ]
    }
   ],
   "source": [
    "variables_to_restore =  slim.get_variables(scope=\"ENSAI/EN_Model9\" )   #list of variables to restore\n",
    "restore_file = \"data/trained_weights/model_9.ckpt\"\n",
    "restorer = tf.train.Saver(variables_to_restore)\n",
    "sess.run(tf.global_variables_initializer())      #initialize variables\n",
    "restorer.restore(sess, restore_file)             # restore our saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MeanSquareCost , y_conv_flipped = cost_tensor(y_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read some lens image files from the disk and add observational effects to them:\n",
    "\n",
    "max_xy_range = 0.5  # xy range of center of the lens. The image is shifted in a central area with a side of max_xy_range (arcsec) during training or testing\n",
    "variable_noise_rms = True   #if True, the noise rms will be chosen randomly for each sample with a max of max_noise_rms\n",
    "max_noise_rms = 0.1  # maximum rms of noise data\n",
    "num_samp = 1000   #number of test samples\n",
    "chunk_size = 50    # batch number: how many test examples to pass at one time.\n",
    "\n",
    "X = np.zeros( ( num_samp , numpix_side * numpix_side ), dtype='float32') ;   #numpy array holding the images\n",
    "Y = np.zeros( ( num_samp , num_out ) , dtype='float32' );                    #numpy array holding the lens parameters (here only used to flip for the x-y ellipticity)\n",
    "Predictions = np.zeros( ( num_samp , num_out ) , dtype='float32' );          #predicted parameters\n",
    "mag = np.zeros((num_samp,1))\n",
    "read_data_batch( X , Y , mag , max_num_test_samples  , 'test')             #read data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = 0.0\n",
    "ind_t = range(num_samp)\n",
    "sum_rms = 0\n",
    "num_chunks = num_samp/chunk_size\n",
    "\n",
    "#loop over our samples (since we can't give all the test data at once because of limited gpu memory)\n",
    "for it in range(num_chunks):\n",
    "        print it\n",
    "        xA = X[ind_t[0+chunk_size*it:chunk_size+chunk_size*it]]\n",
    "        yA = Y[ind_t[0+chunk_size*it:chunk_size+chunk_size*it]]\n",
    "        cost  = cost + sess.run(MeanSquareCost, feed_dict={x: xA, y_: yA})   # evaluate cost\n",
    "        A = sess.run(y_conv , feed_dict={ x: xA})   # A is the network prediction for parameters\n",
    "        B = sess.run(y_conv_flipped , feed_dict={ x: xA})  # B is the same prediction with the ellipticity flipped\n",
    "        Predictions[ind_t[0+chunk_size*it:chunk_size+chunk_size*it],:]  = get_rotation_corrected(A,B,Y[ind_t[0+chunk_size*it:chunk_size+chunk_size*it],:])  # \"Prediction\" is now corrected for the flip.\n",
    "        sum_rms = sum_rms + np.std(Predictions[ind_t[0+chunk_size*it:chunk_size+chunk_size*it],:] -Y[ind_t[0+chunk_size*it:chunk_size+chunk_size*it],:],axis=0)\n",
    "        print('rms error is ' + np.array_str( sum_rms/it  ,precision=2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the recovered parameters (y-axis) against their true values (x-axis)\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.subplot(1, 5, 1)\n",
    "plt.plot(Y[:,0],Predictions[:,0],' .')\n",
    "plt.plot([0 , 3.],[0 , 3.],'--r')\n",
    "plt.xlabel(\"Ein rad (true)\")\n",
    "plt.ylabel(\"Ein rad (predict)\")\n",
    "plt.axis([0 ,3 ,0 ,3])\n",
    "\n",
    "plt.subplot(1, 5, 2)\n",
    "plt.plot(Y[:,1],Predictions[:,1],' .')\n",
    "plt.plot([-1 , 1.],[-1 , 1.],'--r')\n",
    "plt.xlabel(\"elp x (true)\")\n",
    "plt.axis([-1 ,1 ,-1 ,1])\n",
    "\n",
    "\n",
    "plt.subplot(1, 5, 3)\n",
    "plt.plot(Y[:,2],Predictions[:,2],' .')\n",
    "plt.plot([-1 , 1.],[-1 , 1.],'--r')\n",
    "plt.xlabel(\"elp y (true)\")\n",
    "plt.axis([-1 ,1 ,-1 ,1])\n",
    "\n",
    "\n",
    "plt.subplot(1, 5, 4)\n",
    "plt.plot(Y[:,3],Predictions[:,3],' .')\n",
    "plt.plot([-0.4 , 0.4],[-0.4 , 0.4],'--r')\n",
    "plt.xlabel(\"x (true)\")\n",
    "plt.axis([-0.4 ,0.4 ,-0.4 ,0.4])\n",
    "\n",
    "\n",
    "plt.subplot(1, 5, 5)\n",
    "plt.plot(Y[:,4],Predictions[:,4],' .')\n",
    "plt.plot([-0.4 , 0.4],[-0.4 , 0.4],'--r')\n",
    "plt.xlabel(\"y (true)\")\n",
    "plt.axis([-0.4 ,0.4 ,-0.4 ,0.4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a few example of the lenses\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.imshow(X[[i]].reshape(numpix_side,numpix_side),vmin=-0.15,vmax=1.0,cmap='nipy_spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
